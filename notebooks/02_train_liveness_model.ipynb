{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8a1f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94904716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivenessDetector:\n",
    "    def __init__(self):\n",
    "        # Load face cascade\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "                \n",
    "        # More strict thresholds\n",
    "        self.texture_threshold = 25  # Increased for better fake detection\n",
    "        self.motion_history = deque(maxlen=30)\n",
    "        self.consecutive_closed = 0\n",
    "        \n",
    "        # Color analysis history\n",
    "        self.color_variations = deque(maxlen=30)\n",
    "        \n",
    "    def calculate_texture_score(self, face_roi):\n",
    "        \"\"\"Calculate texture complexity - real skin has more variation\"\"\"\n",
    "        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Multiple texture measures\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        \n",
    "        # Local binary pattern-like measure\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "        edge_score = edge_magnitude.std()\n",
    "        \n",
    "        # Combined score\n",
    "        texture_score = laplacian_var + edge_score\n",
    "        return texture_score\n",
    "    \n",
    "    def detect_motion(self, face_coords):\n",
    "        \"\"\"Detect natural micro-movements with stricter requirements\"\"\"\n",
    "        if len(self.motion_history) < 10:\n",
    "            self.motion_history.append(face_coords)\n",
    "            return 0, False\n",
    "        \n",
    "        self.motion_history.append(face_coords)\n",
    "        \n",
    "        # Calculate movement variance\n",
    "        positions = np.array(list(self.motion_history))\n",
    "        variance = np.var(positions, axis=0).sum()\n",
    "        \n",
    "        # Check for natural movement pattern (not too still, not too erratic)\n",
    "        is_natural = 2 < variance < 80\n",
    "        \n",
    "        return variance, is_natural\n",
    "    \n",
    "    def analyze_color_variation(self, face_roi):\n",
    "        \"\"\"Real faces have color variation due to blood flow\"\"\"\n",
    "        # Convert to different color space\n",
    "        hsv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2HSV)\n",
    "        ycrcb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2YCrCb)\n",
    "        \n",
    "        # Calculate color channel variations\n",
    "        h_var = np.var(hsv[:,:,0])\n",
    "        cr_var = np.var(ycrcb[:,:,1])\n",
    "        \n",
    "        color_score = h_var + cr_var\n",
    "        self.color_variations.append(color_score)\n",
    "        \n",
    "        # Real faces should have consistent color variation\n",
    "        if len(self.color_variations) > 20:\n",
    "            variation_consistency = np.std(list(self.color_variations))\n",
    "            return color_score, variation_consistency < 50\n",
    "        \n",
    "        return color_score, False\n",
    " \n",
    "    def check_screen_reflection(self, face_roi):\n",
    "        \"\"\"Detect screen reflections and uniform lighting typical of fake images\"\"\"\n",
    "        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Check for uniform brightness (screens often have this)\n",
    "        brightness_std = np.std(gray)\n",
    "        \n",
    "        # Check for regular patterns (screen pixels)\n",
    "        fft = np.fft.fft2(gray)\n",
    "        fft_shift = np.fft.fftshift(fft)\n",
    "        magnitude_spectrum = np.abs(fft_shift)\n",
    "        \n",
    "        # Screens often have periodic patterns\n",
    "        spectrum_peaks = np.sort(magnitude_spectrum.flatten())[-100:].mean()\n",
    "        \n",
    "        # Low brightness variation + high spectrum peaks = likely screen\n",
    "        is_screen_like = brightness_std < 30 and spectrum_peaks > 10000\n",
    "        \n",
    "        return brightness_std, is_screen_like\n",
    "    \n",
    "    def is_real_face(self, frame, face_coords):\n",
    "        \"\"\"Determine if face is real with stricter criteria\"\"\"\n",
    "        x, y, w, h = face_coords\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Test 1: Texture analysis (stricter)\n",
    "        texture_score = self.calculate_texture_score(face_roi)\n",
    "        texture_passed = texture_score > self.texture_threshold\n",
    "        \n",
    "        # Test 2: Motion analysis (stricter)\n",
    "        motion_score, motion_natural = self.detect_motion((x, y))\n",
    "                \n",
    "        # Test 3: Color variation analysis\n",
    "        color_score, color_natural = self.analyze_color_variation(face_roi)\n",
    "        \n",
    "        # Test 4: Screen reflection detection\n",
    "        brightness_std, is_screen = self.check_screen_reflection(face_roi)\n",
    "        screen_passed = not is_screen\n",
    "        \n",
    "        # Stricter scoring system\n",
    "        score = 0\n",
    "        confidence_factors = []\n",
    "        \n",
    "        if texture_passed:\n",
    "            score += 2  # Texture is very important\n",
    "            confidence_factors.append(\"texture\")\n",
    "        \n",
    "        if motion_natural:\n",
    "            score += 2  # Natural motion is crucial\n",
    "            confidence_factors.append(\"motion\")\n",
    "        \n",
    "        if color_natural:\n",
    "            score += 1\n",
    "            confidence_factors.append(\"color\")\n",
    "        \n",
    "        if screen_passed:\n",
    "            score += 1\n",
    "            confidence_factors.append(\"no_screen\")\n",
    "        else:\n",
    "            score -= 2  # Penalize screen-like characteristics\n",
    "        \n",
    "        # Need at least 5 points to be considered real (stricter)\n",
    "        is_real = score >= 5\n",
    "        \n",
    "        return is_real, {\n",
    "            'texture_score': texture_score,\n",
    "            'texture_passed': texture_passed,\n",
    "            'motion_score': motion_score,\n",
    "            'motion_natural': motion_natural,\n",
    "            'color_score': color_score,\n",
    "            'brightness_std': brightness_std,\n",
    "            'is_screen_like': is_screen,\n",
    "            'total_score': score,\n",
    "            'max_score': 9,\n",
    "            'confidence_factors': confidence_factors\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "892d0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(duration=10):\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = LivenessDetector()\n",
    "    \n",
    "    print(\"Face Liveness Detection Started\")    \n",
    "    # Timer settings\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Store results for final analysis\n",
    "    all_results = []\n",
    "    face_detected_frames = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Calculate remaining time\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining = max(0, duration - elapsed)\n",
    "        \n",
    "        # Check if time is up\n",
    "        if remaining == 0:\n",
    "            break\n",
    "        \n",
    "        # Flip frame for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detector.face_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100)\n",
    "        )\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            face_detected_frames += 1\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Determine if real or fake\n",
    "            is_real, metrics = detector.is_real_face(frame, (x, y, w, h))\n",
    "            \n",
    "            # Store results\n",
    "            all_results.append({\n",
    "                'is_real': is_real,\n",
    "                'metrics': metrics\n",
    "            })\n",
    "            \n",
    "            # Draw rectangle and label\n",
    "            color = (0, 255, 0) if is_real else (0, 0, 255)\n",
    "            label = \"REAL\" if is_real else \"FAKE/SPOOF\"\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "            cv2.putText(frame, label, (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "            \n",
    "            # Display live metrics\n",
    "            y_offset = y + h + 25\n",
    "            line_height = 18\n",
    "            \n",
    "            cv2.putText(frame, f\"Texture: {metrics['texture_score']:.1f} {'✓' if metrics['texture_passed'] else '✗'}\", \n",
    "                       (x, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, f\"Motion: {metrics['motion_score']:.1f} {'✓' if metrics['motion_natural'] else '✗'}\", \n",
    "                       (x, y_offset + line_height), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, f\"Screen: {'Yes ✗' if metrics['is_screen_like'] else 'No ✓'}\", \n",
    "                       (x, y_offset + line_height*4), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, f\"Score: {metrics['total_score']}/{metrics['max_score']}\", \n",
    "                       (x, y_offset + line_height*5), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 255), 1)\n",
    "        \n",
    "        # Display countdown timer (large and prominent)\n",
    "        countdown_text = f\"{int(remaining)}\"\n",
    "        cv2.putText(frame, countdown_text, (frame.shape[1]//2 - 30, 80), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 255, 255), 4)\n",
    "        \n",
    "        # Display instructions\n",
    "        cv2.putText(frame, \"Smile, life is beautiful :) \", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Face Liveness Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Analyze results\n",
    "    if all_results:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LIVENESS DETECTION RESULT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        real_count = sum(1 for r in all_results if r['is_real'])\n",
    "        total_count = len(all_results)\n",
    "        \n",
    "        avg_texture = np.mean([r['metrics']['texture_score'] for r in all_results])\n",
    "        avg_motion = np.mean([r['metrics']['motion_score'] for r in all_results])\n",
    "        avg_brightness = np.mean([r['metrics']['brightness_std'] for r in all_results])\n",
    "        screen_detections = sum(1 for r in all_results if r['metrics']['is_screen_like'])\n",
    "        \n",
    "        # Evaluation criteria\n",
    "        texture_ok = avg_texture > detector.texture_threshold\n",
    "        motion_ok = 2 < avg_motion < 80\n",
    "        screen_ok = screen_detections < (total_count * 0.3)\n",
    "        \n",
    "        criteria_passed = sum([texture_ok, motion_ok, screen_ok])\n",
    "        probability = (real_count / total_count) * 100\n",
    "        \n",
    "        final_verdict = \"REAL\" if criteria_passed >= 2 and probability >= 60 else \"FAKE\"\n",
    "        confidence = min(probability, 95) if final_verdict == \"REAL\" else max(100 - probability, 60)\n",
    "        \n",
    "        print(f\"\\nVerdict: {final_verdict}\")\n",
    "        print(f\"Confidence: {confidence:.1f}%\\n\")\n",
    "        \n",
    "        print(f\"Texture: {avg_texture:.1f} (need >{detector.texture_threshold}) {'✓' if texture_ok else '✗'}\")\n",
    "        print(f\"Motion: {avg_motion:.1f} (need 2-80) {'✓' if motion_ok else '✗'}\")\n",
    "        print(f\"Screen-like: {screen_detections}/{total_count} frames {'✓' if screen_ok else '✗'}\")\n",
    "        \n",
    "        print(f\"\\nReason: \", end=\"\")\n",
    "        if final_verdict == \"REAL\":\n",
    "            reasons = []\n",
    "            if texture_ok: reasons.append(\"natural texture\")\n",
    "            if motion_ok: reasons.append(\"natural motion\")\n",
    "            if screen_ok: reasons.append(\"no screen artifacts\")\n",
    "            print(\", \".join(reasons))\n",
    "        else:\n",
    "            reasons = []\n",
    "            if not texture_ok: reasons.append(\"flat texture\")\n",
    "            if not motion_ok: reasons.append(\"unnatural motion\")\n",
    "            if not screen_ok: reasons.append(\"screen detected\")\n",
    "            print(\", \".join(reasons))\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n❌ No face detected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d123435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Liveness Detection Started\n",
      "\n",
      "============================================================\n",
      "LIVENESS DETECTION RESULT\n",
      "============================================================\n",
      "\n",
      "Verdict: FAKE\n",
      "Confidence: 100.0%\n",
      "\n",
      "Texture: 508.5 (need >25) ✓\n",
      "Motion: 6246.7 (need 2-80) ✗\n",
      "Screen-like: 358/455 frames ✗\n",
      "\n",
      "Reason: unnatural motion, screen detected\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
